import streamlit as st
import pandas as pd
import google.generativeai as genai
from rapidfuzz import fuzz, process
import unidecode
import json
import os
import re
import time
from datetime import datetime

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(page_title="PharmaMatch: Chi Tiáº¿t 5 Yáº¿u Tá»‘", layout="wide")
st.title("ðŸ’Š PharmaMatch: Mapping Chi Tiáº¿t (Batch 5 & Trá»ng Sá»‘)")

# --- 2. CÃC HÃ€M Xá»¬ LÃ TEXT & Sá» ---
def normalize_text(text):
    if pd.isna(text): return ""
    return unidecode.unidecode(str(text).lower()).strip()

def extract_numbers(text):
    """Láº¥y táº­p há»£p sá»‘ tá»« chuá»—i Ä‘á»ƒ so sÃ¡nh hÃ m lÆ°á»£ng."""
    if pd.isna(text): return set()
    nums = re.findall(r"\d+\.?\d*", str(text))
    return set(nums)

def get_match_quality(score):
    """Chuyá»ƒn Ä‘iá»ƒm sá»‘ thÃ nh chá»¯ Ä‘Ã¡nh giÃ¡."""
    if score >= 95: return "Ráº¥t cao"
    if score >= 80: return "Cao"
    if score >= 60: return "Trung bÃ¬nh"
    if score > 0: return "Tháº¥p"
    return "KhÃ´ng khá»›p"

# --- 3. LOAD DATA VTMA ---
@st.cache_data
def load_vtma_data():
    try:
        path = "data/vtma_standard.csv"
        # Há»— trá»£ tÃ¬m file náº¿u lá»¡ Ä‘áº·t sai tÃªn folder
        if not os.path.exists(path):
            if os.path.exists("Data/vtma_standard.csv"): path = "Data/vtma_standard.csv"
            else: return None
            
        df = pd.read_csv(path)
        # Chuáº©n hÃ³a dá»¯ liá»‡u chuáº©n
        df['norm_name'] = df['ten_thuoc'].apply(normalize_text)
        df['norm_ingre'] = df['hoat_chat'].apply(normalize_text)
        df['norm_strength'] = df['ham_luong'].apply(normalize_text)
        df['norm_manu'] = df['ten_cong_ty'].apply(normalize_text)
        df['norm_form'] = df['dang_bao_che'].apply(normalize_text)
        return df
    except:
        return None

# --- 4. Gá»ŒI AI (BATCH PROCESSING - 5 Sáº¢N PHáº¨M) ---
def ai_process_batch(product_list, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        items_str = "\n".join([f"- ID_{i}: {p}" for i, p in enumerate(product_list)])
        
        prompt = f"""
        PhÃ¢n tÃ­ch danh sÃ¡ch thuá»‘c sau:
        {items_str}
        
        Tráº£ vá» JSON List Objects (khÃ´ng Markdown), má»—i object gá»“m:
        - "id": "ID_..." (giá»¯ nguyÃªn ID)
        - "brand_name": TÃªn thÆ°Æ¡ng máº¡i (Biá»‡t dÆ°á»£c).
        - "active_ingredient": Hoáº¡t cháº¥t chÃ­nh.
        - "strength": HÃ m lÆ°á»£ng/Ná»“ng Ä‘á»™ (VD: 500mg, 10%).
        - "manufacturer": TÃªn hÃ£ng/ThÆ°Æ¡ng hiá»‡u.
        - "dosage_form": Dáº¡ng bÃ o cháº¿.
        """
        
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        data = json.loads(text)
        return {item['id']: item for item in data}
    except:
        return {}

# --- 5. LOGIC TÃNH ÄIá»‚M CHI TIáº¾T (5 TIÃŠU CHÃ) ---
def compare_detailed(ai_data, row):
    """
    TÃ­nh Ä‘iá»ƒm tá»•ng há»£p vÃ  tráº£ vá» chi tiáº¿t tá»«ng thÃ nh pháº§n.
    """
    # 1. TÃŠN THÆ¯Æ NG Máº I (40%)
    ai_name = normalize_text(ai_data.get('brand_name', ''))
    score_name_raw = fuzz.token_set_ratio(ai_name, row['norm_name'])
    score_total = score_name_raw * 0.4
    
    # 2. HOáº T CHáº¤T (20%)
    ai_ingre = normalize_text(ai_data.get('active_ingredient', ''))
    score_ingre_raw = fuzz.token_sort_ratio(ai_ingre, row['norm_ingre'])
    score_total += score_ingre_raw * 0.2
    
    # 3. HÃ€M LÆ¯á»¢NG (20%) - Logic Sá»‘ há»c
    ai_strength = normalize_text(ai_data.get('strength', ''))
    ai_nums = extract_numbers(ai_strength)
    row_nums = extract_numbers(row['norm_strength'])
    
    score_str_raw = 0
    if ai_nums and row_nums:
        # Náº¿u táº­p sá»‘ khá»›p nhau -> Tuyá»‡t Ä‘á»‘i 100 Ä‘iá»ƒm thÃ nh pháº§n
        if ai_nums.issubset(row_nums) or row_nums.issubset(ai_nums):
            score_str_raw = 100
        else:
            score_str_raw = 0 
    else:
        # Fallback so sÃ¡nh text náº¿u khÃ´ng cÃ³ sá»‘
        score_str_raw = fuzz.ratio(ai_strength, row['norm_strength'])
    score_total += score_str_raw * 0.2
    
    # 4. NHÃ€ Sáº¢N XUáº¤T (10%)
    ai_manu = normalize_text(ai_data.get('manufacturer', ''))
    score_manu_raw = fuzz.partial_ratio(ai_manu, row['norm_manu'])
    score_total += score_manu_raw * 0.1
    
    # 5. Dáº NG BÃ€O CHáº¾ (10%)
    ai_form = normalize_text(ai_data.get('dosage_form', ''))
    score_form_raw = fuzz.partial_ratio(ai_form, row['norm_form'])
    score_total += score_form_raw * 0.1
    
    return {
        'total_score': round(score_total, 1),
        'details': {
            'name': score_name_raw,
            'ingre': score_ingre_raw,
            'strength': score_str_raw,
            'manu': score_manu_raw,
            'form': score_form_raw
        }
    }

def find_top_matches(ai_data, vtma_df, min_score, top_n):
    # Lá»c nhanh 50 á»©ng viÃªn báº±ng TÃªn
    ai_name = normalize_text(ai_data.get('brand_name', ''))
    candidates = process.extract(ai_name, vtma_df['norm_name'], limit=50, scorer=fuzz.token_set_ratio)
    
    # Chá»‰ láº¥y á»©ng viÃªn cÃ³ tÃªn giá»‘ng > 40%
    indices = [x[2] for x in candidates if x[1] >= 40]
    
    if not indices: return []

    subset = vtma_df.iloc[indices].copy()
    results = []
    
    for idx, row in subset.iterrows():
        # TÃ­nh toÃ¡n chi tiáº¿t
        calc = compare_detailed(ai_data, row)
        
        # Chá»‰ láº¥y káº¿t quáº£ trÃªn ngÆ°á»¡ng
        if calc['total_score'] >= min_score:
            results.append({
                'row': row,
                'score': calc['total_score'],
                'details': calc['details']
            })
            
    # Sáº¯p xáº¿p Ä‘iá»ƒm cao nháº¥t
    results.sort(key=lambda x: x['score'], reverse=True)
    return results[:top_n]

# --- 6. GIAO DIá»†N ---

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Cáº¥u hÃ¬nh")
    api_key = st.text_input("Gemini API Key", type="password")
    if not api_key and "GENAI_API_KEY" in st.secrets:
        api_key = st.secrets["GENAI_API_KEY"]
    
    st.divider()
    threshold = st.slider("Äá»™ chÃ­nh xÃ¡c tá»‘i thiá»ƒu (%)", 0, 100, 50)
    top_n = st.number_input("Sá»‘ mÃ£ VTMA tá»‘i Ä‘a (Top N)", 1, 10, 3)
    
    # CÃ i Ä‘áº·t cá»©ng Batch Size = 5 theo yÃªu cáº§u (hoáº·c cÃ³ thá»ƒ Ä‘á»ƒ slider)
    batch_size = 5 
    st.info(f"âš¡ Äang cháº¡y cháº¿ Ä‘á»™ Batch: {batch_size} sáº£n pháº©m/láº§n")

# Main Screen
vtma_df = load_vtma_data()

# Check file VTMA
if vtma_df is not None:
    st.success(f"âœ… ÄÃ£ táº£i Database VTMA: {len(vtma_df)} mÃ£")
else:
    st.error("âŒ KhÃ´ng tÃ¬m tháº¥y file data/vtma_standard.csv")

# Upload
uploaded = st.file_uploader("Upload File DÆ°á»£c VÆ°Æ¡ng (Excel/CSV)", type=['xlsx', 'csv'])

if uploaded and st.button("ðŸš€ CHáº Y MAPPING"):
    if not api_key:
        st.error("Vui lÃ²ng nháº­p API Key!")
        st.stop()
    if vtma_df is None:
        st.stop()
        
    if uploaded.name.endswith('.csv'): df_in = pd.read_csv(uploaded)
    else: df_in = pd.read_excel(uploaded)
    
    col_name = df_in.columns[0]
    st.info(f"Äang xá»­ lÃ½ cá»™t: {col_name}")
    
    final_results = []
    input_list = df_in[col_name].astype(str).tolist()
    total = len(input_list)
    
    bar = st.progress(0, text="Äang xá»­ lÃ½...")
    
    # VÃ²ng láº·p Batch (BÆ°á»›c nháº£y = 5)
    for i in range(0, total, batch_size):
        batch_items = input_list[i : i + batch_size]
        
        # 1. Gá»i AI cho cáº£ gÃ³i 5 sáº£n pháº©m
        try: ai_dict = ai_process_batch(batch_items, api_key)
        except: ai_dict = {}
        
        # 2. Xá»­ lÃ½ tá»«ng sáº£n pháº©m trong gÃ³i
        for idx, item_name in enumerate(batch_items):
            item_id = f"ID_{idx}"
            ai_info = ai_dict.get(item_id, {})
            
            # TÃ¬m Top N káº¿t quáº£
            matches = find_top_matches(ai_info, vtma_df, threshold, top_n)
            
            # Máº«u dÃ²ng káº¿t quáº£ rá»—ng (Ä‘á»ƒ Ä‘áº£m báº£o cá»™t luÃ´n hiá»‡n)
            base_res = {
                'DV_Input': item_name,
                'VTMA_Code': '', 'Tong_Diem': 0, 'Xep_Hang': '-',
                # 1. TÃªn
                'AI_Ten': ai_info.get('brand_name'), 'VTMA_Ten': '', 'Khop_Ten': '',
                # 2. Hoáº¡t cháº¥t
                'AI_HoatChat': ai_info.get('active_ingredient'), 'VTMA_HoatChat': '', 'Khop_HoatChat': '',
                # 3. HÃ m lÆ°á»£ng
                'AI_HamLuong': ai_info.get('strength'), 'VTMA_HamLuong': '', 'Khop_HamLuong': '',
                # 4. NSX
                'AI_NSX': ai_info.get('manufacturer'), 'VTMA_NSX': '', 'Khop_NSX': '',
                # 5. Dáº¡ng bÃ o cháº¿
                'AI_DangBaoChe': ai_info.get('dosage_form'), 'VTMA_DangBaoChe': '', 'Khop_DangBaoChe': ''
            }
            
            if not matches:
                # KhÃ´ng tÃ¬m tháº¥y -> Ghi 1 dÃ²ng bÃ¡o lá»—i
                res_row = base_res.copy()
                res_row['VTMA_Code'] = 'KhÃ´ng tÃ¬m tháº¥y'
                final_results.append(res_row)
            else:
                # TÃ¬m tháº¥y -> Ghi Top N dÃ²ng
                for rank, m in enumerate(matches, 1):
                    row = m['row']
                    det = m['details']
                    res_row = base_res.copy()
                    
                    res_row.update({
                        'VTMA_Code': row['ma_thuoc'],
                        'Tong_Diem': m['score'],
                        'Xep_Hang': f"Top {rank}",
                        
                        'VTMA_Ten': row['ten_thuoc'], 
                        'Khop_Ten': get_match_quality(det['name']),
                        
                        'VTMA_HoatChat': row['hoat_chat'], 
                        'Khop_HoatChat': get_match_quality(det['ingre']),
                        
                        'VTMA_HamLuong': row['ham_luong'], 
                        'Khop_HamLuong': get_match_quality(det['strength']),
                        
                        'VTMA_NSX': row['ten_cong_ty'], 
                        'Khop_NSX': get_match_quality(det['manu']),
                        
                        'VTMA_DangBaoChe': row['dang_bao_che'], 
                        'Khop_DangBaoChe': get_match_quality(det['form'])
                    })
                    final_results.append(res_row)
        
        # Cáº­p nháº­t thanh tiáº¿n trÃ¬nh
        bar.progress(min((i + batch_size) / total, 1.0))
        time.sleep(1) # Nghá»‰ nháº¹ trÃ¡nh Google cháº·n

    # Hiá»ƒn thá»‹ káº¿t quáº£
    res_df = pd.DataFrame(final_results)
    
    # Sáº¯p xáº¿p Ä‘áº¹p máº¯t
    res_df.sort_values(by=['DV_Input', 'Tong_Diem'], ascending=[True, False], inplace=True)
    
    st.success("âœ… HoÃ n táº¥t!")
    st.dataframe(res_df)
    
    # Download
    os.makedirs('output', exist_ok=True)
    fname = f"output/map_chitiet_{datetime.now().strftime('%H%M')}.xlsx"
    res_df.to_excel(fname, index=False)
    with open(fname, "rb") as f:
        st.download_button("ðŸ“¥ Táº£i BÃ¡o CÃ¡o Chi Tiáº¿t (Excel)", f, file_name="ket_qua_chi_tiet.xlsx")
