import streamlit as st
import pandas as pd
import google.generativeai as genai
from rapidfuzz import fuzz, process
import unidecode
import json
import os
import re
import time
from datetime import datetime

# --- 1. C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="PharmaMatch: Final Batch", layout="wide")

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù TEXT ---
def normalize_text(text):
    if pd.isna(text): return ""
    return unidecode.unidecode(str(text).lower()).strip()

def extract_numbers(text):
    """
    L·∫•y t·∫≠p h·ª£p s·ªë t·ª´ chu·ªói ƒë·ªÉ so s√°nh ch√≠nh x√°c.
    V√≠ d·ª•: '160/4.5' -> {'160', '4.5'}
    """
    if pd.isna(text): return set()
    nums = re.findall(r"\d+\.?\d*", str(text))
    return set(nums)

# --- 3. LOAD DATA VTMA ---
@st.cache_data
def load_vtma_data():
    try:
        # ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n file ƒë√∫ng
        if not os.path.exists("data/vtma_standard.csv"):
            return pd.DataFrame()
            
        df = pd.read_csv("data/vtma_standard.csv")
        # T·∫°o c·ªôt chu·∫©n h√≥a s·∫µn
        df['norm_name'] = df['ten_thuoc'].apply(normalize_text)
        df['norm_strength'] = df['ham_luong'].apply(normalize_text)
        df['norm_ingre'] = df['hoat_chat'].apply(normalize_text)
        df['norm_manu'] = df['ten_cong_ty'].apply(normalize_text)
        return df
    except Exception as e:
        st.error(f"L·ªói ƒë·ªçc file: {e}")
        return pd.DataFrame()

# --- 4. G·ªåI AI THEO BATCH (G·ªòP NHI·ªÄU D√íNG) ---
def ai_process_batch(product_list, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # T·∫°o prompt danh s√°ch
        items_str = "\n".join([f"- ID_{i}: {p}" for i, p in enumerate(product_list)])
        
        prompt = f"""
        Danh s√°ch thu·ªëc c·∫ßn tr√≠ch xu·∫•t th√¥ng tin:
        {items_str}
        
        Y√™u c·∫ßu tr·∫£ v·ªÅ JSON d·∫°ng List of Objects (Tuy·ªát ƒë·ªëi kh√¥ng Markdown), m·ªói object g·ªìm:
        - "id": "ID_..." (gi·ªØ nguy√™n ID t∆∞∆°ng ·ª©ng)
        - "brand_name": T√™n bi·ªát d∆∞·ª£c
        - "strength": H√†m l∆∞·ª£ng s·ªë (VD: 500mg, 160/4.5). Null n·∫øu kh√¥ng c√≥.
        - "active_ingredient": Ho·∫°t ch·∫•t.
        - "manufacturer": T√™n h√£ng.
        """
        
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        data = json.loads(text)
        
        # Chuy·ªÉn v·ªÅ Dictionary: {'ID_0': {...}, 'ID_1': {...}}
        result_dict = {item['id']: item for item in data}
        return result_dict
        
    except Exception as e:
        return {}

# --- 5. LOGIC MAP PH√ÇN T·∫¶NG (HIERARCHICAL) ---
def hierarchical_match(input_data, vtma_df):
    if not input_data: return None, 0, "L·ªói AI"
    
    input_brand = normalize_text(input_data.get('brand_name', ''))
    input_strength = normalize_text(input_data.get('strength', ''))
    input_ingre = normalize_text(input_data.get('active_ingredient', ''))
    
    # B∆Ø·ªöC 1: L·ªåC THEO T√äN (T√¨m 30 m√£ gi·ªëng t√™n nh·∫•t)
    candidates = process.extract(
        input_brand, 
        vtma_df['norm_name'], 
        limit=30, 
        scorer=fuzz.token_set_ratio
    )
    
    # L·∫•y index c·ªßa c√°c d√≤ng c√≥ t√™n gi·ªëng >= 50%
    candidate_indices = [x[2] for x in candidates if x[1] >= 50]
    
    # --- ƒê√ÇY L√Ä CH·ªñ B·∫†N HAY B·ªä L·ªñI, T√îI ƒê√É KI·ªÇM TRA K·ª∏ ---
    if not candidate_indices:
        return None, 0, "Kh√¥ng t√¨m th·∫•y t√™n"

    subset_df = vtma_df.iloc[candidate_indices].copy()
    
    # B∆Ø·ªöC 2: T√çNH ƒêI·ªÇM CHI TI·∫æT
    results = []
    input_nums = extract_numbers(input_strength)
    
    for idx, row in subset_df.iterrows():
        # ƒêi·ªÉm T√™n (40ƒë)
        name_score = fuzz.token_set_ratio(input_brand, row['norm_name']) * 0.4
        
        # ƒêi·ªÉm H√†m L∆∞·ª£ng (40ƒë) - Logic ng·∫∑t ngh√®o
        str_score = 0
        row_nums = extract_numbers(row['norm_strength'])
        
        if not input_nums:
            # N·∫øu Input kh√¥ng c√≥ s·ªë, so s√°nh text t∆∞∆°ng ƒë·ªëi
            str_score = fuzz.ratio(input_strength, row['norm_strength']) * 0.4
        else:
            # N·∫øu Input c√≥ s·ªë, B·∫ÆT BU·ªòC VTMA ph·∫£i ch·ª©a ƒë·ªß c√°c s·ªë ƒë√≥
            if input_nums.issubset(row_nums) or row_nums.issubset(input_nums):
                str_score = 40
            else:
                str_score = 0 # Ph·∫°t v·ªÅ 0 n·∫øu l·ªách s·ªë (VD: 10 vs 15)
        
        # ƒêi·ªÉm Ho·∫°t ch·∫•t (20ƒë)
        ing_score = fuzz.token_sort_ratio(input_ingre, row['norm_ingre']) * 0.2
        
        final_score = name_score + str_score + ing_score
        
        # L∆∞u l·∫°i k·∫øt qu·∫£
        results.append({'row': row, 'score': final_score})
    
    # S·∫Øp x·∫øp t·ª´ cao xu·ªëng th·∫•p
    results.sort(key=lambda x: x['score'], reverse=True)
    
    if results:
        best = results[0]
        return best['row'], best['score'], "OK"
    else:
        return None, 0, "Kh√¥ng c√≥ k·∫øt qu·∫£"

# --- 6. GIAO DI·ªÜN CH√çNH ---
st.title("üöÄ PharmaMatch: Final Batch Version")
st.info("Phi√™n b·∫£n ·ªïn ƒë·ªãnh: Ch·∫°y Batch 10 SP + Logic H√†m l∆∞·ª£ng ch·∫∑t ch·∫Ω.")

with st.sidebar:
    st.header("C·∫•u h√¨nh")
    api_key = st.text_input("Gemini API Key", type="password")
    # L·∫•y key t·ª´ secrets n·∫øu c√≥
    if not api_key and "GENAI_API_KEY" in st.secrets:
        api_key = st.secrets["GENAI_API_KEY"]
    
    batch_size = st.slider("K√≠ch th∆∞·ªõc l√¥ (Batch Size)", 5, 20, 10)

# Load Data
vtma_df = load_vtma_data()
if vtma_df.empty:
    st.error("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file 'data/vtma_standard.csv'. Vui l√≤ng ki·ªÉm tra l·∫°i folder data.")
    st.stop()

uploaded = st.file_uploader("Upload File D∆∞·ª£c V∆∞∆°ng (Excel/CSV)", type=['xlsx', 'csv'])

if uploaded and st.button("üöÄ CH·∫†Y MAPPING"):
    if not api_key:
        st.error("Vui l√≤ng nh·∫≠p API Key!")
        st.stop()
        
    # ƒê·ªçc file
    if uploaded.name.endswith('.csv'): 
        df_in = pd.read_csv(uploaded)
    else: 
        df_in = pd.read_excel(uploaded)
    
    col_name = df_in.columns[0]
    final_results = []
    
    input_list = df_in[col_name].astype(str).tolist()
    total = len(input_list)
    
    bar = st.progress(0, text="ƒêang x·ª≠ l√Ω...")
    
    # V√≤ng l·∫∑p x·ª≠ l√Ω t·ª´ng l√¥ (Batch Loop)
    for i in range(0, total, batch_size):
        # C·∫Øt l√¥
        batch_items = input_list[i : i + batch_size]
        
        # G·ªçi AI (X·ª≠ l√Ω l·ªói n·∫øu AI ch·∫øt gi·ªØa ch·ª´ng)
        try:
            ai_data_dict = ai_process_batch(batch_items, api_key)
        except:
            ai_data_dict = {}
        
        # X·ª≠ l√Ω t·ª´ng ph·∫ßn t·ª≠ trong l√¥
        for idx_in_batch, item_name in enumerate(batch_items):
            item_id = f"ID_{idx_in_batch}"
            ai_info = ai_data_dict.get(item_id, {})
            
            # Map d·ªØ li·ªáu
            match_row, score, note = hierarchical_match(ai_info, vtma_df)
            
            # T·∫°o d√≤ng k·∫øt qu·∫£
            res_row = {
                'DV_Input': item_name,
                'AI_Info': f"{ai_info.get('brand_name')} {ai_info.get('strength')}",
                'VTMA_Code': '',
                'VTMA_Name': '',
                'VTMA_HamLuong': '',
                'VTMA_HoatChat': '',
                'Score': score,
                'Danh_Gia': 'Th·∫•p'
            }
            
            if match_row is not None:
                res_row.update({
                    'VTMA_Code': match_row['ma_thuoc'],
                    'VTMA_Name': match_row['ten_thuoc'],
                    'VTMA_HamLuong': match_row['ham_luong'],
                    'VTMA_HoatChat': match_row['hoat_chat'],
                    'Danh_Gia': 'Cao' if score > 75 else 'Ki·ªÉm tra'
                })
            
            final_results.append(res_row)
        
        # Update ti·∫øn ƒë·ªô
        prog = min((i + batch_size) / total, 1.0)
        bar.progress(prog, text=f"ƒêang ch·∫°y {min(i + batch_size, total)}/{total}...")
        
        time.sleep(1) # Ngh·ªâ 1s tr√°nh spam

    # Hi·ªÉn th·ªã b·∫£ng k·∫øt qu·∫£
    st.success("Ho√†n th√†nh!")
    res_df = pd.DataFrame(final_results)
    st.dataframe(res_df)
    
    # N√∫t t·∫£i xu·ªëng
    os.makedirs('output', exist_ok=True)
    fname = f"output/final_map_{datetime.now().strftime('%H%M')}.xlsx"
    res_df.to_excel(fname, index=False)
    
    with open(fname, "rb") as f:
        st.download_button("üì• T·∫£i k·∫øt qu·∫£ Excel", f, file_name="ket_qua_map.xlsx")
