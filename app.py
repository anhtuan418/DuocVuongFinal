import streamlit as st
import pandas as pd
from rapidfuzz import fuzz, process
import unidecode
import re
import os
from datetime import datetime

# --- 1. C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="PharmaMatch: Local Offline", layout="wide")
st.title("üíª PharmaMatch: Phi√™n b·∫£n Offline (T·ªëc ƒë·ªô cao)")

# --- 2. C√ÅC H√ÄM X·ª¨ L√ù TEXT & S·ªê H·ªåC ---
def normalize_text(text):
    if pd.isna(text): return ""
    # Chuy·ªÉn v·ªÅ ti·∫øng vi·ªát kh√¥ng d·∫•u, ch·ªØ th∆∞·ªùng
    return unidecode.unidecode(str(text).lower()).strip()

def extract_numbers(text):
    """
    H√†m n√†y thay th·∫ø AI ƒë·ªÉ ƒë·ªçc h√†m l∆∞·ª£ng.
    N√≥ t√¨m t·∫•t c·∫£ c√°c con s·ªë trong chu·ªói. 
    VD: "Panadol Extra 500mg v·ªâ 10" -> T√¨m th·∫•y {500, 10}
    """
    if pd.isna(text): return set()
    # Regex t√¨m s·ªë nguy√™n v√† s·ªë th·∫≠p ph√¢n (VD: 4.5, 0.5)
    nums = re.findall(r"\d+\.?\d*", str(text))
    # L·ªçc b·ªè c√°c s·ªë 0 v√¥ nghƒ©a ·ªü ƒë·∫ßu (n·∫øu c·∫ßn) v√† chuy·ªÉn v·ªÅ set ƒë·ªÉ so s√°nh
    return set(nums)

# --- 3. LOAD DATA VTMA ---
@st.cache_data
def load_vtma_data():
    try:
        # ƒê∆∞·ªùng d·∫´n file
        path = "data/vtma_standard.csv"
        if not os.path.exists(path): return None
        
        df = pd.read_csv(path)
        
        # T·∫°o c·ªôt SEARCH_TEXT g·ªôp t·∫•t c·∫£ th√¥ng tin l·∫°i ƒë·ªÉ t√¨m ki·∫øm t·ªïng qu√°t
        # (V√¨ input D∆∞·ª£c V∆∞∆°ng l√† 1 chu·ªói d√†i, n√™n ta g·ªôp VTMA l·∫°i ƒë·ªÉ so s√°nh t∆∞∆°ng ƒë·ªìng)
        df['norm_search'] = df.apply(lambda x: normalize_text(f"{x['ten_thuoc']} {x['hoat_chat']} {x['ham_luong']} {x['ten_cong_ty']}"), axis=1)
        
        # T·∫°o c√°c c·ªôt chu·∫©n h√≥a ri√™ng l·∫ª ƒë·ªÉ t√≠nh ƒëi·ªÉm chi ti·∫øt
        df['norm_name'] = df['ten_thuoc'].apply(normalize_text)
        df['norm_strength'] = df['ham_luong'].apply(normalize_text)
        
        return df
    except:
        return None

# --- 4. LOGIC MAPPING (THAY TH·∫æ AI B·∫∞NG THU·∫¨T TO√ÅN) ---
def local_match(input_raw, vtma_df):
    """
    Logic kh√¥ng d√πng AI:
    1. Chu·∫©n h√≥a Input.
    2. Qu√©t nhanh t√¨m 30 ·ª©ng vi√™n trong VTMA c√≥ chu·ªói text gi·ªëng Input nh·∫•t.
    3. Soi k·ªπ t·ª´ng ·ª©ng vi√™n: ƒê·∫∑c bi·ªát l√† SO KH·ªöP S·ªê (H√†m l∆∞·ª£ng).
    """
    norm_input = normalize_text(input_raw)
    input_nums = extract_numbers(input_raw) # L·∫•y s·ªë t·ª´ Input
    
    # B∆Ø·ªöC 1: S√ÄNG L·ªåC (T√¨m 30 ·ª©ng vi√™n s√°ng gi√°)
    # So s√°nh Input v·ªõi c·ªôt 'norm_search' (g·ªôp t√™n+ho·∫°t ch·∫•t+h√†m l∆∞·ª£ng) c·ªßa VTMA
    candidates = process.extract(
        norm_input, 
        vtma_df['norm_search'], 
        limit=30, 
        scorer=fuzz.token_set_ratio
    )
    
    # L·∫•y index c·ªßa c√°c ·ª©ng vi√™n
    candidate_indices = [x[2] for x in candidates if x[1] >= 40] # Gi·∫£m ng∆∞·ª°ng xu·ªëng 40 ƒë·ªÉ ko b·ªè s√≥t
    
    if not candidate_indices: return None, 0, "Kh√¥ng t√¨m th·∫•y"

    subset_df = vtma_df.iloc[candidate_indices].copy()
    results = []
    
    # B∆Ø·ªöC 2: CH·∫§M ƒêI·ªÇM CHI TI·∫æT (STRICT MODE)
    for idx, row in subset_df.iterrows():
        # ƒêi·ªÉm t∆∞∆°ng ƒë·ªìng vƒÉn b·∫£n (Max 60ƒë)
        # So s√°nh Input v·ªõi T√™n Thu·ªëc ho·∫∑c Ho·∫°t Ch·∫•t
        text_score = fuzz.token_set_ratio(norm_input, row['norm_search']) * 0.6
        
        # ƒêi·ªÉm S·ªë H·ªçc / H√†m L∆∞·ª£ng (Max 40ƒë) - QUAN TR·ªåNG NH·∫§T
        num_score = 0
        row_nums = extract_numbers(row['ham_luong']) # L·∫•y s·ªë t·ª´ c·ªôt h√†m l∆∞·ª£ng chu·∫©n
        
        if not input_nums:
            # N·∫øu Input kh√¥ng c√≥ s·ªë (VD: "Panadol"), th√¨ b·ªè qua check s·ªë, d·ª±a v√†o text
            num_score = 20 
        else:
            # N·∫øu Input c√≥ s·ªë (VD: "Zinc 10"), VTMA c≈©ng ph·∫£i c√≥ s·ªë 10
            # Logic: T·∫≠p s·ªë c·ªßa VTMA ph·∫£i n·∫±m trong Input ho·∫∑c ng∆∞·ª£c l·∫°i
            # VD: VTMA {10} n·∫±m trong Input {10, 100} -> OK
            common_nums = input_nums.intersection(row_nums)
            
            if common_nums: # N·∫øu c√≥ √≠t nh·∫•t 1 s·ªë tr√πng nhau (VD s·ªë 10)
                num_score = 40
            else:
                # N·∫øu Input c√≥ s·ªë m√† map v√†o d√≤ng kh√¥ng c√≥ s·ªë n√†o tr√πng -> PH·∫†T
                # VD: Input "Zinc 15", Row "Zinc 10" -> Chung s·ªë 0, Ph·∫°t!
                num_score = -50 # Tr·ª´ ƒëi·ªÉm c·ª±c n·∫∑ng ƒë·ªÉ lo·∫°i b·ªè
        
        final_score = text_score + num_score
        results.append({'row': row, 'score': final_score})
    
    # S·∫Øp x·∫øp l·∫•y ƒëi·ªÉm cao nh·∫•t
    results.sort(key=lambda x: x['score'], reverse=True)
    
    if results:
        best = results[0]
        # N·∫øu ƒëi·ªÉm b·ªã √¢m (do ph·∫°t s·ªë) th√¨ coi nh∆∞ kh√¥ng kh·ªõp
        if best['score'] < 30: return None, best['score'], "Sai h√†m l∆∞·ª£ng"
        return best['row'], best['score'], "OK"
    else:
        return None, 0, "Kh√¥ng kh·ªõp"

# --- 5. GIAO DI·ªÜN ---
# Load data ngay khi v√†o
vtma_df = load_vtma_data()

st.sidebar.header("C·∫•u h√¨nh Local")
st.sidebar.info("Ch·∫ø ƒë·ªô n√†y ch·∫°y 100% tr√™n m√°y t√≠nh c·ªßa b·∫°n, kh√¥ng c·∫ßn Internet ƒë·ªÉ g·ªçi AI.")

# Upload
st.subheader("üìÇ 1. T·∫£i file D∆∞·ª£c V∆∞∆°ng c·∫ßn map")
uploaded = st.file_uploader("Ch·ªçn file (Excel/CSV)", type=['xlsx', 'csv'])

if uploaded:
    if uploaded.name.endswith('.csv'): df_in = pd.read_csv(uploaded)
    else: df_in = pd.read_excel(uploaded)
    
    st.write(f"D·ªØ li·ªáu Input: {len(df_in)} d√≤ng.")
    col_name = df_in.columns[0] # L·∫•y c·ªôt ƒë·∫ßu ti√™n
    
    if st.button("üöÄ CH·∫†Y MAPPING (OFFLINE)"):
        if vtma_df is None:
            st.error("‚ùå Ch∆∞a c√≥ file data/vtma_standard.csv")
            st.stop()
            
        results = []
        bar = st.progress(0, text="ƒêang x·ª≠ l√Ω...")
        
        # Ch·∫°y v√≤ng l·∫∑p (R·∫•t nhanh n√™n kh√¥ng c·∫ßn Batch)
        for i, row in df_in.iterrows():
            raw_input = str(row[col_name])
            
            # G·ªçi h√†m map local
            match_row, score, note = local_match(raw_input, vtma_df)
            
            # Ghi k·∫øt qu·∫£
            res = {
                'DV_Input': raw_input,
                'VTMA_Code': '', 'VTMA_Name': '', 'VTMA_HamLuong': '', 'VTMA_HoatChat': '', 'VTMA_NSX': '',
                'Score': score,
                'Danh_Gia': 'Th·∫•p'
            }
            
            if match_row is not None:
                res.update({
                    'VTMA_Code': match_row['ma_thuoc'],
                    'VTMA_Name': match_row['ten_thuoc'],
                    'VTMA_HamLuong': match_row['ham_luong'],
                    'VTMA_HoatChat': match_row['hoat_chat'],
                    'VTMA_NSX': match_row['ten_cong_ty'],
                    'Danh_Gia': 'Cao' if score > 80 else 'Ki·ªÉm tra'
                })
            
            results.append(res)
            # Update progress
            bar.progress((i+1)/len(df_in), text=f"ƒêang ch·∫°y: {raw_input}")
            
        st.success("‚úÖ Ho√†n t·∫•t!")
        res_df = pd.DataFrame(results)
        st.dataframe(res_df)
        
        # Download
        os.makedirs('output', exist_ok=True)
        fname = f"output/local_map_{datetime.now().strftime('%H%M')}.xlsx"
        res_df.to_excel(fname, index=False)
        with open(fname, "rb") as f:
            st.download_button("üì• T·∫£i k·∫øt qu·∫£", f, file_name="ket_qua_local.xlsx")

elif vtma_df is None:
    st.warning("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y file 'data/vtma_standard.csv'. Vui l√≤ng ki·ªÉm tra l·∫°i folder data.")
