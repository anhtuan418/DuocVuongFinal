import streamlit as st
import pandas as pd
import google.generativeai as genai
from rapidfuzz import fuzz
import unidecode
import json
import time
import os
from datetime import datetime

# --- Cáº¤U HÃŒNH ---
st.set_page_config(page_title="DÆ°á»£c VÆ°Æ¡ng Mapping Tool", layout="wide")

def normalize_text(text):
    if pd.isna(text): return ""
    return unidecode.unidecode(str(text).lower()).strip()

# --- Gá»ŒI AI GEMINI ---
def get_ai_info(product_name, api_key):
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        # Prompt Ä‘Æ°á»£c tá»‘i Æ°u Ä‘á»ƒ tráº£ vá» Ä‘Ãºng cáº¥u trÃºc so sÃ¡nh
        prompt = f"""
        PhÃ¢n tÃ­ch thuá»‘c: "{product_name}". 
        Tráº£ vá» JSON keys: 
        "active_ingredient" (hoáº¡t cháº¥t chÃ­nh, tiáº¿ng anh cÃ ng tá»‘t), 
        "brand_name" (tÃªn biá»‡t dÆ°á»£c ngáº¯n gá»n), 
        "strength" (hÃ m lÆ°á»£ng sá»‘+Ä‘Æ¡n vá»‹), 
        "manufacturer" (tÃªn hÃ£ng sáº£n xuáº¥t),
        "dosage_form" (dáº¡ng bÃ o cháº¿: viÃªn, gÃ³i, á»‘ng...).
        Náº¿u khÃ´ng rÃµ thÃ¬ Ä‘á»ƒ null.
        """
        response = model.generate_content(prompt)
        text = response.text.replace('```json', '').replace('```', '').strip()
        return json.loads(text)
    except:
        return {}

# --- TÃNH ÄIá»‚M KHá»šP (LOGIC Má»šI CHO FILE VTMA CHUáº¨N) ---
def calculate_score(input_item, db_row):
    score = 0
    
    # 1. SO KHá»šP HOáº T CHáº¤T (Quan trá»ng nháº¥t - 40%)
    # So cá»™t 'hoat_chat' (Cá»™t D trong file VTMA)
    if input_item.get('active_ingredient'):
        score += fuzz.token_sort_ratio(normalize_text(input_item['active_ingredient']), normalize_text(db_row['hoat_chat'])) * 0.4
    
    # 2. SO KHá»šP HÃ€M LÆ¯á»¢NG (30%)
    # So cá»™t 'ham_luong' (Cá»™t G trong file VTMA)
    if input_item.get('strength'):
        s_score = fuzz.ratio(normalize_text(input_item['strength']), normalize_text(db_row['ham_luong']))
        score += s_score * 0.3
        
    # 3. SO KHá»šP TÃŠN THÆ¯Æ NG Máº I (20%)
    # So cá»™t 'ten_thuoc' (Cá»™t C - tÃªn ngáº¯n gá»n nhÆ° A.T DOMPERIDON) thay vÃ¬ tÃªn Ä‘áº§y Ä‘á»§
    brand_score = fuzz.token_set_ratio(normalize_text(input_item.get('brand_name','')), normalize_text(db_row['ten_thuoc']))
    score += brand_score * 0.2
    
    # 4. NHÃ€ Sáº¢N XUáº¤T (10%)
    # So cá»™t 'ten_cong_ty' (Cá»™t F - AN THIEN_A.T PHARM)
    if input_item.get('manufacturer'):
        manu_score = fuzz.partial_ratio(normalize_text(input_item['manufacturer']), normalize_text(db_row['ten_cong_ty']))
        score += manu_score * 0.1
        
    return round(score, 1)

# --- GIAO DIá»†N ---
st.title("ðŸ’Š DÆ°á»£c VÆ°Æ¡ng Mapping Tool (PhiÃªn báº£n VTMA Chuáº©n)")

with st.sidebar:
    st.header("CÃ i Ä‘áº·t")
    user_api_key = st.text_input("Gemini API Key", type="password")
    if not user_api_key and "GENAI_API_KEY" in st.secrets:
        user_api_key = st.secrets["GENAI_API_KEY"]
        
    threshold = st.slider("Äá»™ chÃ­nh xÃ¡c (%)", 0, 100, 50)
    top_n = st.number_input("Sá»‘ mÃ£ gá»£i Ã½", 1, 10, 3)

# Load Data VTMA
try:
    vtma_df = pd.read_csv("data/vtma_standard.csv")
    st.success(f"âœ… ÄÃ£ táº£i {len(vtma_df)} mÃ£ VTMA. Há»‡ thá»‘ng sáºµn sÃ ng!")
except FileNotFoundError:
    st.error("âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file data/vtma_standard.csv. HÃ£y cháº¯c cháº¯n anh/chá»‹ Ä‘Ã£ lÆ°u file vÃ o Ä‘Ãºng thÆ° má»¥c data.")
    st.stop()
except Exception as e:
    st.error(f"âŒ Lá»—i Ä‘á»c file CSV: {e}. HÃ£y Ä‘áº£m báº£o file CSV Ä‘Æ°á»£c lÆ°u vá»›i Encoding UTF-8.")
    st.stop()

# Upload File DÆ°á»£c VÆ°Æ¡ng
uploaded = st.file_uploader("Chá»n file Danh má»¥c DÆ°á»£c VÆ°Æ¡ng (Excel/CSV)", type=['xlsx', 'csv'])

if uploaded and st.button("ðŸš€ CHáº Y MAPPING"):
    if not user_api_key:
        st.warning("âš ï¸ ChÆ°a nháº­p API Key!")
        st.stop()
        
    if uploaded.name.endswith('.csv'): df_in = pd.read_csv(uploaded)
    else: df_in = pd.read_excel(uploaded)
    
    col_name = df_in.columns[0]
    st.info(f"Äang xá»­ lÃ½ cá»™t tÃªn: {col_name}")
    
    results = []
    bar = st.progress(0)
    
    for i, row in df_in.iterrows():
        raw = str(row[col_name])
        ai_data = get_ai_info(raw, user_api_key)
        
        matches = []
        for _, v_row in vtma_df.iterrows():
            s = calculate_score(ai_data, v_row)
            if s >= threshold:
                matches.append({
                    'ma_thuoc': v_row['ma_thuoc'],
                    'ten_thuoc': v_row['ten_thuoc'],
                    'hoat_chat': v_row['hoat_chat'],
                    'ham_luong': v_row['ham_luong'],
                    'ten_cong_ty': v_row['ten_cong_ty'], # Láº¥y chÃ­nh xÃ¡c cá»™t F
                    'dang_bao_che': v_row['dang_bao_che'],
                    'score': s
                })
        
        matches = sorted(matches, key=lambda x: x['score'], reverse=True)[:top_n]
        
        if not matches:
            results.append({'DV_Input': raw, 'Status': 'KhÃ´ng tÃ¬m tháº¥y'})
        else:
            for m in matches:
                # Logic Ä‘Ã¡nh giÃ¡
                danh_gia = 'Cao' if m['score'] > 85 else ('Trung bÃ¬nh' if m['score'] > 60 else 'Tháº¥p')
                
                results.append({
                    'DV_Input': raw,
                    'AI_Hieu_La': f"{ai_data.get('brand_name')} / {ai_data.get('active_ingredient')} / {ai_data.get('strength')}",
                    'VTMA_Code': m['ma_thuoc'],
                    'VTMA_Name': m['ten_thuoc'],
                    'VTMA_HoatChat': m['hoat_chat'],
                    'VTMA_HamLuong': m['ham_luong'],
                    'VTMA_NSX': m['ten_cong_ty'],
                    'Match_Score': m['score'],
                    'Do_Tin_Cay': danh_gia
                })
        bar.progress((i+1)/len(df_in))
        
    res_df = pd.DataFrame(results)
    st.dataframe(res_df)
    
    # Download logic
    os.makedirs('output', exist_ok=True)
    fname = f"output/ket_qua_{datetime.now().strftime('%H%M')}.xlsx"
    res_df.to_excel(fname, index=False)
    with open(fname, "rb") as f:
        st.download_button("ðŸ“¥ Táº£i káº¿t quáº£ Mapping", f, file_name="ket_qua_map.xlsx")
        
